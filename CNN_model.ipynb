{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57224fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6394267984578837\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random \n",
    "random.seed(42)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "print(random.random())\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8edd1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "num_classes = 3\n",
    "train_dir = r'C:\\Users\\dkang\\OneDrive\\Documents\\Gray Scale Image Code\\Conductor_research\\Image\\GVN\\CNN_GVN_Train_Img'\n",
    "test_dir = r'C:\\Users\\dkang\\OneDrive\\Documents\\Gray Scale Image Code\\Conductor_research\\Image\\GVN\\CNN_GVN_Test_Img'\n",
    "\n",
    "batch_size=32 #standard batch size; smaller the better at generalization\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for folder in os.scandir(train_dir):\n",
    "    count = 0  # Initialize count to 0\n",
    "    for entry in os.scandir(train_dir + '/' + folder.name):\n",
    "        img = cv2.imread(train_dir + '/' + folder.name + '/' + entry.name, cv2.IMREAD_GRAYSCALE)  # Read image using OpenCV\n",
    "        print(train_dir + folder.name + '/' + entry.name, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))  # Resize image to specified size\n",
    "        img = np.array(img, dtype='float32')  # Convert image to float32 type\n",
    "        img = img/255  # Normalize pixel values to range [0, 1]\n",
    "\n",
    "        X_train.append(img)  # Append image to training data\n",
    "\n",
    "        if folder.name == 'only_cor':\n",
    "            y_train.append(0)  # Assign class label 0 for 'only corroded' \n",
    "        elif folder.name == 'only_def':\n",
    "            y_train.append(1)  # Assign class label 1 for 'only defective' \n",
    "        elif folder.name == 'def_cor':\n",
    "            y_train.append(2)  # Assign class label 2 for 'defective & corroded'\n",
    "\n",
    "        count += 1  # Increment count for each image\n",
    "\n",
    "    print(f\"Folder: {folder.name}, Total Training Images: {count}\")\n",
    "\n",
    "X_train = np.array(X_train)  # Convert training data to numpy array\n",
    "y_train = np.array(y_train)  # Convert class labels to numpy array\n",
    "# Add a channel dimension since the images are grayscale\n",
    "X_train = np.expand_dims(X_train, axis=-1)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1, \n",
    "    height_shift_range=0.1, \n",
    "    vertical_flip=True)  \n",
    "\n",
    "num_augmented_samples = 1000  # Desired total number of augmented samples\n",
    "steps_per_epoch = num_augmented_samples // batch_size\n",
    "\n",
    "X_aug_list = []\n",
    "y_aug_list = []\n",
    "\n",
    "for _ in range(steps_per_epoch):\n",
    "    X_batch, y_batch = next(datagen.flow(X_train, y_train, batch_size=batch_size, shuffle=True, seed = 42))\n",
    "    X_aug_list.append(X_batch)\n",
    "    y_aug_list.append(y_batch)\n",
    "\n",
    "X_aug = np.concatenate([X_train] + X_aug_list, axis=0)\n",
    "y_aug = np.concatenate([y_train] + y_aug_list, axis=0)\n",
    "\n",
    "\n",
    "print(f\"Original training data shape: {X_train.shape}\")\n",
    "print(f\"Original training data shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"Augmented training data shape: {X_aug.shape}\")\n",
    "print(f\"Augmented training Y data shape: {y_aug.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deac516",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, shuffle=True, stratify=y_train, random_state=123)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_aug, y_aug, test_size=0.25, shuffle=True, stratify=y_aug, random_state=42)\n",
    "\n",
    "# K-cross validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "# Lists to store metrics\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train, y_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        # Input layer: assuming the input image size is (IMG_SIZE, IMG_SIZE, 1) for grayscale images\n",
    "        Conv2D(filters=16, kernel_size=(7, 7), activation='relu', kernel_initializer=initializer, input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.5),\n",
    "        Flatten(), #Flatten the 3D tensor to 1D\n",
    "        # Fully connected layers\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.15),\n",
    "        Dense(667, activation='relu'), #100/.15 = 667 to compensate for the loss through dropout\n",
    "        Dense(3, activation='softmax')  # Assuming 3 classes for classification\n",
    "    ])\n",
    "    initializer = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "    opt = optimizers.Adam(learning_rate=0.0003)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    # Train the model\n",
    "    checkpointer = ModelCheckpoint(filepath=\"main.keras\", verbose=1, save_best_only=True)\n",
    "    history = model.fit(X_train_fold, \n",
    "                        y_train_fold, \n",
    "                        epochs=20, \n",
    "                        validation_data=(X_val_fold, y_val_fold), \n",
    "                        batch_size=32, \n",
    "                        shuffle=True, \n",
    "                        callbacks=[checkpointer])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1] * 100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no += 1\n",
    "    \n",
    "\n",
    "# After k-cross validation, train on the entire training data\n",
    "model = tf.keras.Sequential([\n",
    "    # Input layer: assuming the input image size is (IMG_SIZE, IMG_SIZE, 1) for grayscale images\n",
    "    Conv2D(filters=16, kernel_size=(7, 7), activation='relu', kernel_initializer=initializer, input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.5),\n",
    "    Flatten(), #Flatten the 3D tensor to 1D\n",
    "    # Fully connected layers\n",
    "    Dense(100, activation='relu'),\n",
    "    Dropout(0.15),\n",
    "    Dense(667, activation='relu'), #100/.15 = 667 to compensate for the loss through dropout\n",
    "    Dense(3, activation='softmax')  # Assuming 3 classes for classification\n",
    "])\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=42)\n",
    "opt = optimizers.Adam(learning_rate=0.0003)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# Compute the expected initial loss for a softmax classifier\n",
    "expected_initial_loss = -np.log(1.0 / num_classes)\n",
    "print(f\"Expected Initial Loss: {expected_initial_loss:.6f}\")\n",
    "\n",
    "#Measure the actual initial loss on the validation set before training\n",
    "initial_loss, initial_accuracy = model.evaluate(X_val, y_val, batch_size=32)\n",
    "print(f\"Actual Initial Loss: {initial_loss:.6f}\")\n",
    "print(f\"Actual Initial Accuracy: {initial_accuracy:.6f}\")\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"main.keras\", verbose=1, save_best_only=True)\n",
    "\n",
    "#Train the model\n",
    "# with augmentation \n",
    "history = model.fit(X_aug, y_aug, epochs=20, validation_data=(X_val, y_val), batch_size=32, shuffle=True, callbacks=[checkpointer])\n",
    "# without augmentation\n",
    "# history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), batch_size=32, shuffle=True, callbacks=[checkpointer])\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(len(acc_per_fold)):\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26293587",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bbcb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for folder in os.scandir(test_dir):\n",
    "    for entry in os.scandir(test_dir + '/' + folder.name):\n",
    "        img = cv2.imread(test_dir + '/' + folder.name + '/' + entry.name, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = np.array(img, dtype='float32')\n",
    "        img = img / 255\n",
    "\n",
    "        X_test.append(img)\n",
    "\n",
    "        if folder.name == 'only_cor':\n",
    "            y_test.append(0)\n",
    "        elif folder.name == 'only_def':\n",
    "            y_test.append(1)\n",
    "        elif folder.name == 'def_cor':\n",
    "            y_test.append(2)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(f\"X test data shape: {X_test.shape}\")\n",
    "print(f\"Y test data shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# Number of classes in your classification problem\n",
    "num_classes = 3\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "model.load_weights(\"main.keras\")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "y_test_sparse = np.argmax(y_test_one_hot, axis=1)\n",
    "loss, accuracy = model.evaluate(X_test, y_test_sparse, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669bdf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Generate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "class_names = ['only_cor', 'only_def', 'def_cor']  # Replace with your class names\n",
    "report = classification_report(y_test, y_pred_classes, target_names=class_names)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ace347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
